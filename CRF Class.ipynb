{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Made by: João Vitor Andrioli de Souza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRFinternalFunctions:\n",
    "    def sent2features(self,sent,TokensEmVolta,atributos,fitting = False):        \n",
    "        if fitting == True:\n",
    "            return [self.word2features(list(zip(*list(zip(*sent))[:-1])), i,TokensEmVolta,atributos) for i in range(len(sent))]\n",
    "        else:\n",
    "            st = []\n",
    "            for sn in sent:\n",
    "                if type(sn) == str:\n",
    "                    st.append((sn,))\n",
    "                else:\n",
    "                    st.append(sn)\n",
    "            return [self.word2features(st, i,TokensEmVolta,atributos) for i in range(len(sent))]\n",
    "    \n",
    "    def sent2labels(self,sent):\n",
    "        return [tokenlabeladc[-1] for tokenlabeladc in sent]\n",
    "    \n",
    "    \n",
    "    def word2features(self,doc, i,TokensEmVolta,atributosOriginal): #TokensEmVolta    deve ser     1,2,3 ou 4\n",
    "   \n",
    "        def vogaisconsecutivas(word):\n",
    "            vogal =  [1 if letra in 'aeiou' else 0 for letra in word]\n",
    "            for y in vogal:\n",
    "                vogal = [vogal[x-1] + 1 if vogal[x-1] > 0 and vogal[x] > 0 else vogal[x] for x in range(len(vogal))] \n",
    "            if len(vogal) == 0:\n",
    "                return '0'\n",
    "            return str(max(number for number in vogal))\n",
    "\n",
    "        def consoantesconsecutivas(word):\n",
    "            vogal =  [1 if letra in 'bcdfghjklmnpqrstvwxyz' else 0 for letra in word]\n",
    "            for y in vogal:\n",
    "                vogal = [vogal[x-1] + 1 if vogal[x-1] > 0 and vogal[x] > 0 else vogal[x] for x in range(len(vogal))]    \n",
    "            if len(vogal) == 0:\n",
    "                return '0'\n",
    "            return str(max(number for number in vogal))\n",
    "\n",
    "        def MaiusculoEmVolta(doc,i,emvolta):\n",
    "            try:\n",
    "                return False if False in [False if upmvolt(doc[i-x][0]) == False else True for x in range(-emvolta,emvolta+1)] else True\n",
    "            except:\n",
    "                return MaiusculoEmVolta(doc,i,emvolta-1)\n",
    "\n",
    "\n",
    "        upmvolt =          lambda word: word.isupper() or word.isnumeric()\n",
    "        contavogais =      lambda word: str(len(list(filter(lambda letras: letras in 'aeiou',word)))) #Abbreviation nao tem acento\n",
    "        semvogal =         lambda word: True if contavogais(word) == 0 else False\n",
    "        maior2consoantes = lambda word: True if int(consoantesconsecutivas(word)) > 2 else False\n",
    "        possuiacento =     lambda word: True if True in [True if x in 'áéíóúãõà' else False for x in word] else False\n",
    "        hasPunctuation =   lambda word: True if True in [True if x in \".,:\\\\|^~'*-+!=&%#@\" else False for x in word] else False\n",
    "        lenghtUm =         lambda word: True if len(word) == 1 else False\n",
    "        hasHyphen =        lambda word: True if True in [True if x == \"-\" else False for x in word] else False\n",
    "        letterAndDigit =   lambda word: True if True in [True if x in \"qwertyuiopasdfghjklçzxcvbnm\" and True in [True if y in \"0987654321\" else False for y in word] else False for x in word] else False\n",
    "        hasUpper =         lambda word: True if True in [True if x in \"QWERTYUIOPÇLKJHGFDSAZXCVBNM\" else False for x in word] else False\n",
    "        hasUnderscore =    lambda word: True if True in [True if x == \"_\" else False for x in word] else False\n",
    "        hasBrackets =      lambda word: True if True in [True if x in \"][}{()\" else False for x in word] else False\n",
    "        DigitoVirgulaDigito = lambda word: True if True in [True if  word[x].isdigit() and (word[x+1] == \".\" or word[x+1] == \",\") and word[x+2].isdigit() else False for x in range(len(word)-2)] else False\n",
    "\n",
    "\n",
    "        def generate_ngrams(snt, n, posicao):\n",
    "\n",
    "            tokens = []\n",
    "            for w in snt:\n",
    "                try:\n",
    "                    tokens.append(w[0].lower())\n",
    "                except:\n",
    "                    tokens.append(\"\")\n",
    "                    \n",
    "            ngrams = zip(*[tokens[i:] for i in range(n)])\n",
    "            res = [\" \".join(ngram) for ngram in ngrams]\n",
    "\n",
    "            try:\n",
    "                return res[posicao]\n",
    "            except:\n",
    "                try:\n",
    "                    return res[len(res)-1]\n",
    "                except:\n",
    "                    return '-1'\n",
    "\n",
    "        #################################\n",
    "        features = []\n",
    "        atributos = atributosOriginal\n",
    "        \n",
    "        for posicao in range(-TokensEmVolta,TokensEmVolta+1):\n",
    "            eos = False \n",
    "            bos = False        \n",
    "            if i-posicao == 0:\n",
    "                bos = True        # Indicate that it is the 'beginning of a document'\n",
    "            if i-posicao == len(doc):\n",
    "                eos = True # Indicate that it is the 'end of a document'\n",
    "                \n",
    "            if i-posicao >= 0 and i-posicao < len(doc):\n",
    "             \n",
    "            \n",
    "                try:\n",
    "                    word = doc[i-posicao][0]\n",
    "                except:\n",
    "                    break\n",
    "             \n",
    "            \n",
    "            \n",
    "                featuresAdicionais = []\n",
    "                if len(doc[i-posicao]) > 1:\n",
    "                    for FAD in doc[i-posicao][1:]:\n",
    "                        featuresAdicionais.append(FAD)\n",
    "                \n",
    "                posicaostr = str(-posicao)\n",
    "                \n",
    "                lista_atributos = [\n",
    "                    posicaostr+':word.normal=' + word,\n",
    "                    posicaostr+':word.isupper=%s' % word.isupper(),\n",
    "                    posicaostr+':word.istitle=%s' % word.istitle(),\n",
    "                    posicaostr+':word.isdigit=%s' % word.isdigit(),\n",
    "                    posicaostr+':word.size=%s' % len(word),\n",
    "                    posicaostr+':numerovogais=' + contavogais(word),\n",
    "                    posicaostr+':vogaisconsecutivas='+vogaisconsecutivas(word),\n",
    "                    posicaostr+':consoantesconsecutivas='+consoantesconsecutivas(word),\n",
    "                    posicaostr+':maior2consoantes=%s'% maior2consoantes(word),    \n",
    "                    posicaostr+':possuiacento=%s'% possuiacento(word),   \n",
    "                    posicaostr+':semvogal=%s'% semvogal(word),\n",
    "                    posicaostr+':sentence.isupper=%s' % MaiusculoEmVolta(doc,i,TokensEmVolta),\n",
    "                    posicaostr+':word.tempontuacao=%s' % hasPunctuation(word),\n",
    "                    posicaostr+':word.islower=%s' % word.islower(),\n",
    "                    posicaostr+':word.tamanhoum=%s' % lenghtUm(word),\n",
    "                    posicaostr+':word.letraenumero=%s' % letterAndDigit(word),\n",
    "                    posicaostr+':word.temmaiuscula=%s' % hasUpper(word),\n",
    "                    posicaostr+':word.temunderscore=%s' % hasUnderscore(word),\n",
    "                    posicaostr+':word.tembrackets=%s' % hasBrackets(word),\n",
    "                    posicaostr+':word.temhyphen=%s' % hasHyphen(word),\n",
    "                    posicaostr+':word.numeroflutuante=%s' % DigitoVirgulaDigito(word),\n",
    "                    posicaostr+':word.bigram=' + generate_ngrams(doc, 2, i-posicao),\n",
    "                    posicaostr+':word.trigram=' + generate_ngrams(doc, 3, i-posicao)\n",
    "                ]\n",
    "    \n",
    "                for indexa,FAD in enumerate(featuresAdicionais):\n",
    "                     lista_atributos.append(posicaostr+':featureAdicional='+ str(indexa) + str(FAD))\n",
    "    \n",
    "            \n",
    "                atributos_escolhidos = [posicaostr+':word.lower=' + word.lower(),'EOS=%s'%eos,'BOS=%s'%bos]\n",
    "                \n",
    "                if len(atributos) != len(lista_atributos):\n",
    "                    #print(\"mascara de atributos selecionados possui tamanho errado\")\n",
    "                    #print(\"tamanho atributos selecionados:\",len(atributos))\n",
    "                    #print(\"tamanho atributos usados      :\",len(lista_atributos))\n",
    "                    #print(\"treinando com todos os atributos!\")\n",
    "                    atributos = []\n",
    "                    \n",
    "                if len(atributos) == 0:\n",
    "                    atributos = [1 for _ in range(len(lista_atributos))]\n",
    "\n",
    "                    \n",
    "                for l in range(len(atributos)):\n",
    "                    if atributos[l] == 1:\n",
    "                        atributos_escolhidos.append(lista_atributos[l])\n",
    "                \n",
    "                atributos = atributosOriginal\n",
    "                \n",
    "                features.extend(atributos_escolhidos)\n",
    "                \n",
    "    \n",
    "        return features\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRFmodel:\n",
    "    def __init__(self,*sklearnCRFmodel):\n",
    "        self.cro = []\n",
    "        if len(sklearnCRFmodel) > 0:\n",
    "            self.sklearnCRFmodel = sklearnCRFmodel[0]\n",
    "        else:\n",
    "            import sklearn_crfsuite\n",
    "            self.sklearnCRFmodel = sklearn_crfsuite.CRF( algorithm='pa', c = 1.0 ,pa_type = 1 , max_iterations=100, all_possible_transitions=True)\n",
    "        self.tokensAround = 4\n",
    "        \n",
    "        \n",
    "    def fit(self,dados):\n",
    "        X = [CRFinternalFunctions().sent2features(s,self.tokensAround,self.cro,fitting = True) for s in dados]\n",
    "        y = [CRFinternalFunctions().sent2labels(s) for s in dados]\n",
    "        \n",
    "        self.sklearnCRFmodel = self.sklearnCRFmodel.fit(X, y)\n",
    "        \n",
    "    def predict(self,Xraw):        \n",
    "        X = [CRFinternalFunctions().sent2features(s,self.tokensAround,self.cro) for s in Xraw]\n",
    "\n",
    "        return self.sklearnCRFmodel.predict(X)\n",
    "    \n",
    "    def selectFeatures(self,mask):\n",
    "        self.cro = mask\n",
    "    \n",
    "class CRFutil:\n",
    "    def saveModel(self,CRFmodel,modelNameFile):\n",
    "        import pickle\n",
    "        file = open(modelNameFile+\".txt\", \"wb\")\n",
    "        pickle.dump(CRFmodel, file)\n",
    "\n",
    "    def loadModel(self,modelNameFile):\n",
    "        import pickle\n",
    "        file = open(modelNameFile+\".txt\", \"rb\")\n",
    "        return pickle.load(file)\n",
    "    \n",
    "    def openConllFile(self,inputNameFile):\n",
    "        with open(inputNameFile, 'r') as f:  \n",
    "            sentenceS = []\n",
    "            sentence  = []\n",
    "            for line in f:\n",
    "                line = line[:-1]\n",
    "                if line.strip() == \"\":\n",
    "                    sentenceS.append(sentence)\n",
    "                    sentence  = []\n",
    "                else:\n",
    "                    sentence.append(line.split(\" \"))\n",
    "        return sentenceS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences (TRAIN):  5740\n",
      "[[['POI', 'B-Abbreviation'], ['DE', 'O'], ['LAVAGEM', 'O'], ['+', 'O'], ['CURETA', 'O'], ['DE', 'O'], ['TECIDO', 'O'], ['NECROTICO', 'O'], ['.', 'O']], [['18', 'O'], [':', 'O'], ['00', 'O'], [':', 'O'], ['PACIENTE', 'O'], ['RETORNOU', 'O'], ['DO', 'O'], ['CC', 'B-Abbreviation'], ['LUCIDO', 'O'], [',', 'O'], ['ORIENTADO', 'O'], [',', 'O'], ['COMUNICATIVO', 'O'], [';', 'O'], ['MANTEM', 'O'], ['AVP', 'B-Abbreviation'], ['COM', 'O'], ['STP', 'B-Abbreviation'], ['.', 'O']]]\n",
      "Number of sentences (TEST):  1913\n",
      "[[['ACESSO', 'O'], ['VENOSO', 'O'], ['PERIFERICO', 'O'], ['COM', 'O'], ['FLUIDOTERAPIA', 'O'], ['EM', 'O'], ['CURSO', 'O'], ['EM', 'O'], ['MSE', 'B-Abbreviation'], ['.', 'O']], [['ABDOME', 'O'], ['PLANO', 'O'], [',', 'O'], ['FLACIDO', 'O'], ['.', 'O']]]\n",
      "Prediction format:\n",
      "[['ACESSO', 'VENOSO', 'PERIFERICO', 'COM', 'FLUIDOTERAPIA', 'EM', 'CURSO', 'EM', 'MSE', '.'], ['ABDOME', 'PLANO', ',', 'FLACIDO', '.']]\n"
     ]
    }
   ],
   "source": [
    "#corpus deve ser uma lista de sentencas, sentencas deve ser uma lista de tokens e cada token uma tripla(palavra,featureAdicional1,featureAdicional2,TAG)\n",
    "#primeiro item é palavra, ultimo é label, os n do meio são features adicionais\n",
    "samplecorpusformat = [[['POI', 'B-Abbreviation'],  ['DE', 'O'],  ['LAVAGEM', 'O'],  ['+', 'O'],  ['CURETA', 'O'],  ['DE', 'O'],  ['TECIDO', 'O'],  ['NECROTICO', 'O'],  ['.', 'O']], [['18', 'O'],  [':', 'O'],  ['00', 'O'],  [':', 'O'],  ['PACIENTE', 'O'],  ['RETORNOU', 'O'],  ['DO', 'O'],  ['CC', 'B-Abbreviation'],  ['LUCIDO', 'O'], [',', 'O'],  ['ORIENTADO', 'O'],  [',', 'O'],  ['COMUNICATIVO', 'O'],  [';', 'O'], ['MANTEM', 'O'],  ['AVP', 'B-Abbreviation'],  ['COM', 'O'],  ['STP', 'B-Abbreviation'], ['.', 'O']]]\n",
    "\n",
    "#################################################\n",
    "\n",
    "# You can use the openConllFile function if the data is a file in connl format\n",
    "\n",
    "# create the CRF util class\n",
    "utils = CRFutil()\n",
    "inputNameFile = \"AbbreviationDadostrain.txt\"\n",
    "TRAININGcorpus = utils.openConllFile(inputNameFile)\n",
    "\n",
    "print(\"Number of sentences (TRAIN): \",len(TRAININGcorpus))\n",
    "print(TRAININGcorpus[:2])\n",
    "\n",
    "#################################################\n",
    "\n",
    "inputNameFile = \"AbbreviationDadosdev.txt\"\n",
    "PREDICTIONcorpus = utils.openConllFile(inputNameFile)\n",
    "\n",
    "print(\"Number of sentences (TEST): \",len(PREDICTIONcorpus))\n",
    "print(PREDICTIONcorpus[:2])\n",
    "\n",
    "\n",
    "# The prediction data must not have the labels\n",
    "def getSentencesAndFeaturesOnly(dados):\n",
    "    newDados = []\n",
    "    for sent in dados:\n",
    "        try:\n",
    "            newDados.append(list(zip(*list(zip(*sent))[:-1])))\n",
    "        except:\n",
    "            pass\n",
    "    return newDados\n",
    "\n",
    "PREDICTIONSentences = getSentencesAndFeaturesOnly(PREDICTIONcorpus)\n",
    "print(\"Prediction format:\")\n",
    "print(PREDICTIONSentences[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the CRF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      "[['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Abbreviation', 'O'], ['O', 'O', 'O', 'O', 'O']]\n"
     ]
    }
   ],
   "source": [
    "# creating the CRF Model\n",
    "modeloCRF = CRFmodel()\n",
    "\n",
    "# training the model\n",
    "modeloCRF.fit(TRAININGcorpus)\n",
    "\n",
    "#################################################\n",
    "\n",
    "# file name for saving and loading the model\n",
    "modelNameFile = 'CRFtestmodel'\n",
    "\n",
    "# create the CRF util class\n",
    "utils = CRFutil()\n",
    "\n",
    "# SAVING the model\n",
    "utils.saveModel(modeloCRF,modelNameFile)\n",
    "\n",
    "# LOADING the model\n",
    "modeloCRF = utils.loadModel(modelNameFile)\n",
    "\n",
    "#################################################\n",
    "\n",
    "# predicting\n",
    "# The prediction data must not have the labels\n",
    "y_pred = modeloCRF.predict(PREDICTIONSentences)\n",
    "\n",
    "print(\"Prediction:\")\n",
    "print(y_pred[:2])\n",
    "\n",
    "# if you want to save the y_pred, you can use the same functions .saveModel and .loadModel, \n",
    "# because they are the basic pickle dump and load!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can define your owm crf model from sklearn\n",
    "import sklearn_crfsuite\n",
    "sklearnCRFmodel = sklearn_crfsuite.CRF( algorithm='pa', c = 1.0 ,pa_type = 1 , max_iterations=100, all_possible_transitions=True)\n",
    "modeloCRF = CRFmodel(sklearnCRFmodel) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can select only the features you want to use with a binary mask\n",
    "featuresMask = dict()\n",
    "featuresMask['word.normal']            = 1\n",
    "featuresMask['word.isupper']           = 0\n",
    "featuresMask['word.istitle']           = 0\n",
    "featuresMask['word.isdigit']           = 0\n",
    "featuresMask['word.size']              = 0\n",
    "featuresMask['numerovogais']           = 1\n",
    "featuresMask['vogaisconsecutivas']     = 1\n",
    "featuresMask['consoantesconsecutivas'] = 0\n",
    "featuresMask['maior2consoantes'  ]     = 1\n",
    "featuresMask['possuiacento' ]          = 0\n",
    "featuresMask['semvogal']               = 0\n",
    "featuresMask['sentence.isupper']       = 0\n",
    "featuresMask['word.tempontuacao']      = 1\n",
    "featuresMask['word.islower']           = 1\n",
    "featuresMask['word.tamanhoum']         = 0\n",
    "featuresMask['word.letraenumero']      = 0\n",
    "featuresMask['word.temmaiuscula']      = 1\n",
    "featuresMask['word.temunderscore']     = 0\n",
    "featuresMask['word.tembrackets']       = 1\n",
    "featuresMask['word.temhyphen']         = 0\n",
    "featuresMask['word.numeroflutuante']   = 0\n",
    "featuresMask['word.bigram']            = 1\n",
    "featuresMask['word.trigram']           = 0\n",
    "\n",
    "#The input must be a binary list!\n",
    "featuresSelected = list(featuresMask.values())\n",
    "#featuresSelected = [1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0 ,1 ,0]\n",
    "\n",
    "#You have to run this before calling .fit and .predict\n",
    "modeloCRF.selectFeatures(featuresSelected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
